# 全体戦略
以下の手順で実行する．
参考にすべき資料は，このREADME.mdと，[Kaggle本]($DOCS/books/Kaggleで勝つデータ分析の技術.md)である．

## 手順
1. 性能指標/ロス関数を考える．
    - Kaggle本「タスクと評価指標」や，"最適化"を参考にすること．
1. split(train/dev/test)を作成する．
    - Kaggle本「モデルの評価」を参考にすること．
1. 特徴量を考える．
    - ただし，この段階では，「ベースライン特徴量」でよい．
1. ベースラインモデルを築く．
    - ハイパラも「ベースラインパラメータ」でよい．
1. 提出してみる
    - 手元のバリデーションデータでの性能と，とリーダーボード上の性能に，大きな差異が無いことを確認する．そうでなければ，全ての前提が崩れる．
        * CodaLabの場合，タスクによっては，提出したsubmitをリーダーボードから"隠す"こともできる．おそらく，主催者側が設定できるようになっているのだろう．
    - 提出データのフォーマットが合っているか，確認する．
    - 評価終了直前まで，リーダーボードに最良の結果を出さない．過熱を防ぐため．
        * 自分のモデルの性能がリーダーボード上でどの位置にあるかは，「手元のdevでの性能」と[リーダーボードでの性能]の差から，推測可能である．
1. ハイパラチューニングを行う．
1. ensembleを行う．
1. (性能が足りない場合) エクストラモデル，タスク特有の工夫を埋め込んだモデルを築く．
1. 必要であれば，創意工夫により，スコアを高める．
    - 後述の，「ドメイン特有の定石」「タスク特有の手法」
    - 特徴量, モデル, ..etc
1. 以上を必要なら何回か繰り返し，バリデーションデータ・リーダーボードを見ながら，性能を向上させていく．

## 手法の"コスパ" を意識する．
手法Xを以下のようにカテゴライズすると，この順で"コスパ"(効果/労力 の期待値) が悪くなっていく．
これを意識して，コスパの良い手法から試すこと．
1. コンペの定石
    - Pros:
        * 実装コストが低い．
        * タスクによらず，汎用的に効果が確認されている．
    - Cons:
    - ex.) ハイパラチューニング, CV, アンサンブル, ..
2. ドメイン特有の定石
    - Pros:
        * 特定ドメインでは，汎用的に効果が確認されている．
    - Cons:
    - ex.)
        * 転移学習
        * マルチタスク学習
        * 画像のaugmentation
        * 言語モデルの事前学習
3. それ以外の創意工夫
    - Pros: オリジナリティが出る．
    - Cons:
        * 効果が未知数．
        * コストが高い．エラー解析等が必要となるため．
    - まずはエラー解析から始める必要がある．
    - ex.) 新規特徴量, マルチモーダル, データ拡張, 新規モデル, ..

## 実装上のポイント
* データはできるだけCSVでやり取りする．形もできるだけ揃える．
    - train/valid/testを合わせて，ユニークなindexを作るべきである．
        * ReferTableRegressorのため．
    - pandas -> sklearn の流れを出せるため．
    - 特に，入力データや，その予測値．
    - **各データには，ユニークなindexを付与し，ずっと使い回すこと．**
    - 列名は分かりやすいものをつけておくこと．
    - 区切り文字は"\t"にする．生テキストは，"\t"をスペースに置換する．
    - indexを付ける．indexは全てのプログラムで唯一のものを共有する．行番号で管理しない．
    - タスクによらない"マスターDataFrame"を作成し，それのみをやり取りして前処理を行う．どうしても切り出したい場合は，前処理が終わる直前にする．
    - preprocessing/splitはipynb上で行う．EDAも付随することが多いため．
    - routine
        ```python
            from ai_competition import data_processing
            df = data_processing.read_csv(input_path, 0)
            data_processing.to_csv(df, output_path, ..)
        ```
* ensembleでは，y_predを入力として必要とする．これもできるだけCSVにする．
* preprocess/split/train .. とプログラムを分ける．
