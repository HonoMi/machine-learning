# todo




# Stability
* 背景
    - PAC理論は極めて一般的な条件下で成り立つ．
    - もう少し強い条件を課して，汎化誤差上限を出すことができる．
    - そのような条件の１つとして，`stability`が挙げられる．
* 結果
    - \beta-stable な機械学習器に対して，汎化誤差上限は
        * `(汎化誤差) <= (経験誤差) + \beta + (2m\beta + M) x sqrt(log(1/delta) / 2m)` (FML Theorem 14.2)
            - 第２項に，仮説空間の複雑度が現れていないことが特徴．これは，複雑度に関してはより強い`beta-stable`という条件が課されているためである．
            - `\beta < sqrt(1/m)` の時に，経験誤差が汎化誤差に収束する．
            - 
    - kernel機械学習器は，stableである．
    - 既存のloss関数に正則化項を加えることで，stableな問題に変換することができる． (UML Corollary 13.8-13.10)
        * UML Corollary 13.8: 正則化項項を加えることにより， 1. 経験誤差への悪影響の項(第二項) 2. 過学習を防ぐ項(大参考)
        * UML Corollary 13.9: うまい\lambdaを選んで1と2の効果のバランスを取ることにより，収束させることができる．
        * 応用: 正則化項ありのloss関数で，正則化項の強さ(\lambda)に関してSRMする．
            - 手順
                1. オリジナルの問題に比べて，stabilityが増すので，その分だけ汎化誤差上限が小さくなる．
                2. 一方で，\lambdaに関するSRMによって，汎化誤差上限が増す．
            - なぜうまくいくのか．
                * 2の効果よりも1の効果の方が大きい場合は，この学習がうまくいく．

## 参考資料
* UML 13章
* FML 14章




# ポイント
* PAC理論は，データのサンプリングに起因する揺らぎを扱う．逆に，それ以外の揺らぎ(アルゴリズムに起因する揺らぎ等)は理論の適用範囲外である．




# 汎化誤差上限
* notation
    - m: 学習サンプル数

1. 最も一般的な条件における，汎化誤差上限
    - `(汎化誤差) <= (経験誤差) + (モデルの複雑度に依存する項)`
    - `(モデルの複雑度に依存する項) ~ sqrt[ { (VC次元) + log(1/delta) } / m]`
        * UML theorem6.8 をeについて解けばよい．
2. \beta-stableな機械学習器の，汎化誤差上限
    - `(汎化誤差) <= (経験誤差) + (sqrt(m) x \beta(m))`
        * よって，`\beta(m) < sqrt(1/m)`ならば，汎化誤差は経験誤差で近似できる．




# モデル選択とvalidation
* ERM vs モデル選択
    - ERM
        * ある仮説空間Hの中で，経験誤差を最小にするhを選ぶ．
            - しばしば，最適化アルゴリズムを用いて行われる．
                * 例: SGD
            - なぜ汎化誤差を最小にするhを選べないかというと，
                * 経験誤差を最小にするには，学習データを用いて最適化アルゴリズムを適用すればよい．
                * 一方，汎化誤差を最小にするには，Hの中の全てのhに対して，validationデータでの誤差を計算しなければならない．これは計算量的に不可能である．
        * 例
            - 線形回帰の重みを最適化する．
            - ニューラルネットワークの重みを最適化する．
    - モデル選択
        * ある仮説空間Hの中で，汎化誤差を最小にするhを選ぶ．
            - validationデータでの誤差によって，汎化誤差を推定する．
            - ERMではできなかった汎化誤差の計算が，モデル選択ではできる理由．仮説空間Hに含まれる仮説の数が小さいので，仮説全て(あるいは，一部でよ)に対してvalidationデータの誤差を計算することが，可能となるからである．
            - 特に，異なるタイプのモデルから最良のモデルを選択する場合，「経験誤差から汎化誤差を推定して比較をする」ということはできない．なぜならば， 1. モデルのタイプが異なるので，モデルの複雑度が異なる．よって，汎化誤差の比較の際に，モデルの複雑度の計算を省くことができない． 2. モデルの複雑度は一般には，計算できない．
        * 例
            - 最適なepoch数を選ぶ．
                * 仮説空間 = 取りうるepoch数の空間
            - 最適なモデルのタイプ(例: NN vs SVM)を選ぶ ．
                * 仮説空間 = 取りうるモデルタイプの空間
            - 最適なhyperparameterを選ぶ．
                * 仮説空間 = 取りうるhyperparameterの空間
* ただし，当然，「モデル選択」というプロセスも過学習する可能性はある．
    - モデル選択の汎化誤差
        * `(汎化誤差) - (validation誤差) < sqrt[ log{ 2|H| / delta } / 2m ]`
            - UML Corollary4.6 有限集合の汎化誤差と等しい．
* hold-out-validation vs cross-validation
    - hold-out-validationの誤差が，汎化誤差のunbiased-estimatorであることは，示されている．
        * UML theorem11.1
    - CVはhold-out-validationの強い版だと考えられるが，定量的な解析はできていないという．




# AdaBoostでなぜ性能が向上するのか．
* AdaBoostは一般的なensembleとは違い，モデル間の依存を利用する．
* 具体的には，他のモデルが間違えたサンプルの重みを大きくしてモデルを学習し，最後に適切な重みでensembleする．
* 手法から分かるように，AdaBoostはチートに近い．よって，一般のensembleでの性能向上する理由とは大きく違うと考えられる．
* 詳しくは，UML 10章の議論を参考にされたい．




# Baggingでなぜ性能が向上するのか．
下記において，性能向上要因が性能劣化要因を上回る場合に，Baggingで性能が向上すると考えられる．
* 性能向上要因
    - 一般的なensembleの性能向上要因
    - \beta-stablenessの向上．baggingでは学習データをサンプリングして予測の平均を取るので，\beta-stable度を直接向上させることができると考えられる．\beta(m)の関数系が変わり，mに関してより強い減少関数になると考えられる．
* 性能劣化要因
    - 学習データ量が減ることによって，汎化誤差の推定性能上限が上がること．
        * 汎化誤差上限の第二項が，mに関して増加関数であることによる．
    - 学習データ量が減ることによって，経験誤差が大きくなること．
        * 線形回帰のような単純な機械学習の場合は，学習データ量が経れば経験誤差は小さくなることが多いだろう．一方，ニューラルネットワークのような表現抽出に基づく機械学習器の場合，表現学習が進まなくなることにより，経験誤差が大きくなる可能性はある．

## 参考資料
* Enselbme本 3章



# Ensemble

## Ensembleでなぜ性能が向上するのか．

以下，"Ensemble Methods"の4章イントロに従って議論を進める．
ensembleによって性能が上がる理由は，以下の３点の解決による．
1. Statistical Issue
    - Empirical Risk Minimizationを満たす仮説hが複数ある場合，それらの平均取ることにより，「ERMの選択」という確率変数に関する汎化誤差の期待値を最大化する．
        * 具体的には，「hの平均予測器」「単一のhによる予測器」という2つの予測器に対して，上記確率変数に関する汎化誤差の期待値を比べると，前者の方が高くなっているはず．例えば3.4を参考にすれば計算できそう．
    - 本議論はおそらく，PAC理論でいうところのvariance，すなわちデータのサンプリングに起因するvarianceと結びついていると考えられる．
        * PAC理論ではERMを満たすhは１つしか存在しないとして議論が進むことが多い．
        * 一方，「複数ERMが起こりうる」という現象は結局，仮説集合のVC次元に比してサンプル数が小さいことから起こるので，PAC理論の考え方の範囲内であるはず．
        * 実際，ERMを満たすhが複数存在する場合でも，汎化誤差を出すことはできるのではないだろうか？
2. Computational Issue
    - この議論は，PAC理論の範囲外である．PACは，「ERMを満たす仮説は見つけることができる」という立場であるため．
3. Representational Issue
    - これは，PAC理論のbiasの考え方と完全に符合する．一言でいうと，ensembleは，極めてよい帰納的バイアスを持った仮説空間のことである．なぜならば，
        1. ensembleの仮説空間はベースモデルを含むので，ensemble仮説空間のbiasは，少なくともベースモデルの中で最小のbiasを達成できる．
        2. ベースモデルにvariationがあれば(ベースモデルの相関が小さければ)，更に小さいbiasを達成できる可能性がある．
        3. varianceに関して: ensembleのVC次元は，ベースモデルのそれに比べて大きい．よって，1・2によるbiasの低減効果との兼ね合いによって，性能が向上するか否かが決まる．
            - ensembleモデルのVC次元は，最大で(base modelのVC次元) x (meta-classifierのVC次元) である．
            - 実用上は，きちんとvalidationすればよいというだけの話．ensembleで上がればそれを採用し，そうでなければ，baseを採用すればよい．
    特に，アンサンブルの仮説空間がベースモデルを含む場合は，バリアンスが小さければベースモデルよりも汎化誤差が上がるだろう。

上記の1, 2は，PAC理論を「ERMの選択が確率的なものになる」というように拡張することにより，記述することができるようになると思う．これはおそらく，自明な拡張である．

* あるいは，もう少し解析的な見方もできる．(ensemble本3章)
    - ２値分類問題において，base modelがindependentでありかつ，それらの誤差が0.5以下の場合，これらのvotingで性能が向上することが示せる．ensembleが誤りを起こすのは，N個のbase modelのうち半分以上が間違った場合だけだが，この確率はbsae modelが間違う確率に比べてよほど小さくなる．
    - これも結局，「ensembleはバイアス項を小さくする」という一例である．

## EnsembleのVC次元
* UMLの10.3.1参照
* 上記の通り，ensembleによって，biasは小さくなる．
* varianceに関しては，大まかに，
    - VCdim(ensemble(B, N)) = O( VCdim(B) x N ) である．
* bias-varianceを裏付ける実験事実
    - semeval task7
        1. データセットが少量の際(Humicroeditのみの時)には，stacking ensembleにおいて，モデル数が5x7程度から性能劣化が始まった．これは，varianceに起因すると思われる．
        2. 一方，データセットが2倍程度になった後(FunLinesも含めた時)では，20x7程度まで性能が上がっていった．
* 更に，平均アンサンブルは1点からなる仮説集合の追加で済んでいる．

## variance整理
* PAC理論
    - variance:
        * データのサンプリングに起因するもの．
            - 対策: cross-validation, Structured Risk Minimization, 等
* ensemble
    - variance:
        * データのサンプリングに起因するもの．
            - 対策: ensemble
        * 不完全な最適化に起因するもの．
            - 対策: ensemble

## 参考資料
* Enselbme本 4章



# 参考資料
* [Ensemble Methods: Foundations and Algorithms](https://www.amazon.co.jp/dp/B00A8SNJ7K/)
    - "Ensemble本"
* [Foundations of Machine Learning, second edition](https://www.amazon.co.jp/dp/B08BT4MJ29/)
    - "FML"
* [Understanding Machine Learning: From Theory to Algorithms](https://www.amazon.co.jp/dp/B00J8LQU8I/)
    - "UML"
